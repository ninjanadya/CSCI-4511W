Do you believe there are reasons to be concerned about advances of AI?
	*AI taking away jobs from many
		-Most people still rely on selling their time to have enough income to sustain themselves and their families.
		-Not everyone has the opportunity to receive higher education, so they rely on providing the physical work to ensure financial stability.
		(https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence)
		
	*Wealth gap
		- With AI, there will be fewer humans in the workforce, which means less money to be distributed, and therefor goes straight to the owners of the companies.
		- The owners of companies that use AI will become wealthier, and it will be more difficult to compete for those who don't have the accessability to AI and machines.
	
	*Reliability
		- AI are just computers; machines. They are not complex enough to think "creatively" as a human would in certain situations when it comes to problem solving, rather they think "rationally" as they try to grapple a problem with the best possible solution based on what it already knows. So if a new kind of problem arises, something not yet implemented into the AI's memory, the computer could be baffled, and either cease to function, provide a solution be it very optimal or decent enough to get by, or make a mistake.
		- A computer can sometimes be "fooled" in ways that humans wouldn't be.
		
	*Singularity
		- AI developing to such an extent where it becomes more intelligent than humans, with the ability to predict, learn, adapt, and defend itself.


What specific advances are you concered about?
	*The inability to understand values.
		- AI just does what it is told, in a literal sense. When you ask of it to find the fastest route to someplace, it will do what it deems most efficient, but that doesn't necessarily mean it will be in agreement with the person being driven.
		- This comes down to tradeoffs with Ultility-based agents. 
		https://futureoflife.org/2019/08/14/how-can-ai-systems-understand-human-values/?cn-reloaded=1
		  They will likely make decisions based on efficiency and not so much the more complex rationality of humans i.e. depending on certain situations, what needs to be prioritized regardless of probability.
		- Humans' priorities can change constantly, and and AI may not know or understand human behavior well enough to make decisions similar to that of a human in complex situations.

Why?
	AI use formulas and statistics to determine probability of success, in then aids in formulating a solution to the problem at hand. This is different than the way humans would normally think, as humans make decisions based on past experiences, the complexity of the current situation, things they have learned that may pertain to the situation, and most importantly, emotion.
	It is not confirmed whether AI can feel emotion the same way a human or other living thing can, nor is it confirmed that it ever will, and that's why simulating human behavior and/or understanding it could be near if not completely impossible, especially if humans can't always predict how other humans will react in certain situations.

What steps you believe governments, industries, and academics should take to address these issues?
- yes:
https://phys.org/news/2019-04-artificial-intelligence-emulate-human-behaviors.html


